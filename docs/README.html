<!doctype html><html lang="en"><meta charset="utf-8"><title>README</title><style>body{font-family:system-ui,Segoe UI,Arial,sans-serif;margin:2rem;line-height:1.6;max-width:980px} pre,code{background:#f6f8fa;padding:.2rem .4rem;border-radius:4px}</style><body><p>﻿# RCFD-PCG MVP</p>
<p>âž¡ï¸ Browse recent results and plots: <code>results/index.html</code></p>
<p>A minimal Python package implementing Ridge-Corrected Frequent-Directions (RCFD) preconditioning and a PCG solver for tall-skinny least-squares.</p>
<p>Product promise:
- Free, self-serve. No support, no meetings. Upgrade to Pro to unlock advanced features â€” still no support.
- If the proof-pack doesnâ€™t show wins in our recommended regimes, donâ€™t buy.</p>
<h2 id="why-rcfd-pcg-is-a-no-brainer-for-tall-skinny-least-squares">Why RCFD-PCG is a no-brainer for tall-skinny least squares</h2>
<ul>
<li>Reuse wins now: <code>results/bench_sparse_reuse.json</code> and <code>results/single_vs_reuse.html</code> capture end-to-end time dropping from ~0.31 s to ~0.17 s with 36 PCG iterations, while LSQR/LSMR still burn &gt;100 iterations.</li>
<li>Ill-conditioned proof on demand: <code>results/bench_ill_cond.json</code> shows RCFD converging in 3 iterations where LSQR takes 309+, matching dense Cholesky accuracy without dense costs.</li>
<li>Deterministic, inspectable collateral: CLI runs emit shareable JSON/HTML (<code>results/demo_report.html</code>) so buyers can embed metrics in review decks without notebooks.</li>
<li>Drop-in for ML stacks: <code>rcfd_pcg.sklearn.RCFDRidge</code> slots into sklearn pipelines, joblib persistence, and <code>docs/RegimeCookbook.md</code> narrates parameter picks per regime.</li>
</ul>
<h2 id="ten-minute-proof-path">Ten-minute proof path</h2>
<ol>
<li>Install (<code>pip install -e .</code> or grab the wheel artifacts produced by CI).</li>
<li>Run <code>python -m rcfd_pcg.cli demo --out results/demo_report.json --html results/demo_report.html</code> to preheat the solver and generate the HTML summary.</li>
<li>Run the canonical sparse benchmark twice to surface reuse wins:</li>
<li><code>python -m rcfd_pcg.bench --n 20000 --d 200 --sparse --eps 0.25 --tol 1e-6 --repeats 3 --json --out-json results/bench_sparse_single.json</code></li>
<li><code>python -m rcfd_pcg.bench --n 20000 --d 200 --sparse --eps 0.25 --tol 1e-6 --repeats 3 --reuse-precond --json --out-json results/bench_sparse_reuse.json</code></li>
<li>Open <code>results/index.html</code> (or <code>results/single_vs_reuse.html</code>) to walk stakeholders through the before/after artifacts.</li>
<li>Optional: drop in a real dataset with <code>rcfd-pcg --real-dataset 20ng --json</code> to show a like-for-like baseline.</li>
<li>Run <code>python -m examples.proof_pack --results results --out-json results/proof_pack.json --out-html results/proof_pack.html</code> to bundle the JSON + HTML summary (<code>results/proof_pack.html</code>). See <code>docs/ProofPack.md</code> for a shareable runbook. You can also automate everything with <code>python scripts/proof_pack_pipeline.py</code>.</li>
</ol>
<p>Share the <code>results/</code> directory or the prebuilt plots in <code>plots/</code> as your proof-pack; everything is deterministic so another laptop reproduces the story. The solver JSON surfaces <code>bail_out</code> and <code>bail_out_details</code> so it's obvious when the auto guardrail skips sketching.</p>
<p><a href="https://github.com/your-org/RCFD/actions/workflows/ci.yml"><img alt="CI" src="https://github.com/your-org/RCFD/actions/workflows/ci.yml/badge.svg" /></a>
<a href="https://codecov.io/gh/your-org/RCFD"><img alt="codecov" src="https://codecov.io/gh/your-org/RCFD/branch/main/graph/badge.svg" /></a></p>
<h2 id="north-star">North star</h2>
<ul>
<li>Let any user prove â€œiterations â†“ ~4Ã—; wallâ€‘clock â†“ 1.5â€“3Ã—â€ for tallâ€‘skinny leastâ€‘squares on their laptop in under 10 minutes, with zero meetings. Convert that proof into design partners and a first paid pilot.</li>
</ul>
<h2 id="status-and-how-to-run">Status and how to run</h2>
<h3 id="whatatms-in-the-repo-and-works-today">Whatâ€™s in the repo and works today</h3>
<ul>
<li>CLIs and selfâ€‘serve spine</li>
<li><code>rcfd-pcg demo</code>: oneâ€‘command demo; emits JSON + HTML report. DONE</li>
<li><code>rcfd-pcg run</code>: run on local files (<code>mm:matrix.mtx</code>, <code>npz:csr.npz</code>, <code>.npy</code>). DONE</li>
<li><code>rcfd-pcg doctor</code>: environment/compat check in JSON or text. DONE</li>
<li>Solver and APIs</li>
<li>Deterministic RCFDâ€‘PCG with bailâ€‘out to LSQR/LSMR when not a fit; JSON diagnostics. DONE</li>
<li>sklearn wrapper <code>rcfd_pcg.sklearn.RCFDRidge</code>; joblib save/load. DONE</li>
<li>Benchmarks and artifacts</li>
<li>Suite runner and plotting: <code>rcfd_pcg.suite</code>, <code>examples/plot_benchmarks.py</code>. DONE</li>
<li>Canonical synthetic sparse benchmarks saved (singleâ€‘shot and reuse) with time_p95/p99: <code>results/bench_sparse_single.json</code>, <code>results/bench_sparse_reuse.json</code></li>
<li>Docs (start here)</li>
<li><code>docs/StartHere.md</code>, <code>docs/BenchmarkGuide.md</code>, <code>docs/RegimeCookbook.md</code></li>
<li>Trust pages: <code>docs/WhenNotToUse.md</code>, <code>docs/Privacy.md</code>; Support: <code>docs/Troubleshooting.md</code></li>
<li>GPU envelope: <code>docs/GPUEnvelope.md</code> (experimental); Spark recipe: <code>examples/spark_recipe.md</code></li>
<li>Packaging</li>
<li>GitHub Actions wheels workflow present. IN PROGRESS</li>
<li>CPU <code>Dockerfile</code> present; local build works; publish pending.</li>
<li>Service</li>
<li><code>examples/service.py</code> (FastAPI) with request limits, timeout, optional token, and <code>/metrics</code>. DONE</li>
<li>Code health</li>
<li>Tests passing locally (Windows). Lints clean for edited files.</li>
</ul>
<h3 id="guardrails-and-how-we-steer-around-them">Guardrails and how we steer around them</h3>
<ul>
<li>Single-shot, small/moderate d: iteration wins lead, but wall-clock may hinge on sketch overhead. Lead with the reuse story (<code>rcfd_pcg.bench --reuse-precond</code>) or let the built-in bail-out keep LSQR/LSMR when they finish faster; docs/BenchmarkGuide.md captures the playbook, and you can tune it with <code>--bail-out-threshold</code> or disable via <code>--no-bail-out</code>.</li>
<li>GPU path is intentionally prototypical; keep it off unless you opt into the envelope in <code>docs/GPUEnvelope.md</code> while we complete the CuPy integration.</li>
<li>Wheels and Docker publishing are baking: run <code>pip install -e .</code> or build straight from the repo today while the release workflow marches toward tagged PyPI pushes (see Roadmap launch lane).</li>
<li>Spark connector remains a recipe; teams use <code>examples/spark_recipe.md</code> until the packaged connector ships.</li>
</ul>
<h3 id="how-to-run-the-essentials">How to run the essentials</h3>
<ul>
<li>Demo (JSON + HTML):</li>
</ul>
<p><code>powershell
python -m rcfd_pcg.cli demo --out results/demo_report.json --html results/demo_report.html</code></p>
<ul>
<li>Single solve from files:</li>
</ul>
<p><code>powershell
python -m rcfd_pcg.cli run --A mm:path/to/matrix.mtx --b vec.npy --out report.json --html report.html</code></p>
<ul>
<li>Doctor:</li>
</ul>
<p><code>powershell
python -m rcfd_pcg.cli doctor --json</code></p>
<ul>
<li>Suite + plots (small demo):</li>
</ul>
<p><code>powershell
python -m rcfd_pcg.suite --n 2000 --d 200 --sparse --eps_list 0.15,0.25 --sketch_dtypes float32 --num_passes_list 1 --threads_list 1 --repeats 1 --out_root results
python -m examples.plot_benchmarks --input results/&lt;printed out_dir&gt; --out plots</code></p>
<ul>
<li>Canonical sparse singleâ€‘shot/reuse (already used):</li>
</ul>
<p><code>powershell
python -m rcfd_pcg.bench --n 20000 --d 200 --sparse --eps 0.25 --tol 1e-6 --repeats 3 --json --out-json results/bench_sparse_single.json
python -m rcfd_pcg.bench --n 20000 --d 200 --sparse --eps 0.25 --tol 1e-6 --repeats 3 --reuse-precond --json --out-json results/bench_sparse_reuse.json</code></p>
<ul>
<li>Service (optional):</li>
</ul>
<p><code>powershell
uvicorn examples.service:app --host 0.0.0.0 --port 8000</code></p>
<h3 id="risks-and-how-to-avoid-them">Risks and how to avoid them</h3>
<ul>
<li>â€œIterations win but time doesnâ€™tâ€: present two tracks (singleâ€‘shot vs reuse) and lead with reuse time wins.</li>
<li>Windows console and package friction: prefer <code>--json</code> or <code>--ascii-default</code>; ship wheels and MSI/winget notes; signed wheels page.</li>
<li>Variability: pin BLAS threads (<code>OPENBLAS_NUM_THREADS=1</code> etc.), warmup runs, use a â€œcontentionâ€‘safeâ€ preset.</li>
<li>Large d memory: use <code>--precond-type blockdiag --num-col-blocks K</code> or spill to disk.</li>
</ul>
<h3 id="where-to-look">Where to look</h3>
<ul>
<li>Roadmap: <code>ROADMAP.md</code></li>
<li>Solver: <code>rcfd_pcg/rcfd.py</code>; CLI: <code>rcfd_pcg/cli.py</code>; Bench: <code>rcfd_pcg/bench.py</code></li>
<li>Trust/support: <code>docs/WhenNotToUse.md</code>, <code>docs/Privacy.md</code>, <code>docs/Troubleshooting.md</code></li>
<li>Start here: <code>docs/StartHere.md</code></li>
<li>Docker: <code>Dockerfile</code></li>
<li>Spark recipe: <code>examples/spark_recipe.md</code></li>
<li>Results/plots: <code>results/</code>, <code>plots/</code></li>
<li>Artifact index: <code>results/index.html</code> (generated via <code>python -m examples.generate_results_index</code>)</li>
</ul>
<h3 id="docker-cpu-quickstart">Docker (CPU) quickstart</h3>
<p>Build locally and run the demo without a local Python install:</p>
<p><code>powershell
docker build -t rcfd-pcg:cpu -f Dockerfile .
docker run --rm -v ${PWD}:/work -w /work rcfd-pcg:cpu \
  python -m rcfd_pcg.cli demo --out results/demo_report.json --html results/demo_report.html</code></p>
<h2 id="install">Install</h2>
<h3 id="from-pypi-releases-010">From PyPI (releases &gt;=0.1.0)</h3>
<p><code>bash
pip install rcfd-pcg</code></p>
<h3 id="from-ghcr-docker">From GHCR (Docker)</h3>
<p><code>bash
docker pull ghcr.io/alexanderluzdh/rcfd:latest
docker run --rm -v ${PWD}:/work -w /work ghcr.io/alexanderluzdh/rcfd:latest rcfd-pcg demo --json</code></p>
<p>For pinned versions, replace <code>latest</code> with your tag (e.g., <code>ghcr.io/alexanderluzdh/rcfd:v0.1.0</code>).</p>
<h3 id="from-source-dev-mode">From source (dev mode)</h3>
<p><code>bash
pip install -e .[dev]</code></p>
<h3 id="from-wheels-ci-artifacts">From wheels (CI artifacts)</h3>
<p>Prebuilt wheels are still produced on tags via GitHub Actions. Download from the workflow artifacts or your release assets:</p>
<p><code>bash
pip install rcfd-pcg-*.whl</code></p>
<h2 id="cli-quickstart">CLI quickstart</h2>
<p><code>bash
rcfd-pcg --n 200000 --d 500 --eps 0.25 --lam 0 --tol 1e-6 --sparse --json</code></p>
<p>Real dataset quickstart (requires scikit-learn):</p>
<p><code>bash
rcfd-pcg --real-dataset 20ng --n-features 1024 --eps 0.25 --tol 1e-6 --json --json-out results/bench_20ng.json
rcfd-pcg --real-dataset rcv1 --n-features 1024 --eps 0.25 --tol 1e-6 --json --json-out results/bench_rcv1.json
rcfd-pcg --real-dataset yearmsd --sample 100000 --eps 0.25 --tol 1e-6 --json --json-out results/bench_yearmsd.json
rcfd-pcg --real-dataset cahousing --eps 0.25 --tol 1e-6 --json --json-out results/bench_cahousing.json</code></p>
<p>Auto mode example (auto epsilon and tuned compression):</p>
<p><code>bash
rcfd-pcg --n 20000 --d 200 --sparse --eps auto --json</code></p>
<h3 id="canonical-benchmarks">Canonical benchmarks</h3>
<p>Use the helper script to run consistent comparisons and optionally save JSON.</p>
<p>Sparse scenario (nâ‰ˆ20k, dâ‰ˆ200):</p>
<p><code>bash
python -m examples.benchmark_canonical --scenario synthetic_sparse \
  --n 20000 --d 200 --repeats 3 --eps 0.25 --threads-compare 1,2 --json \
  --out-json bench_canonical_sparse.json</code></p>
<p>Dense scenario (nâ‰ˆ5k, dâ‰ˆ400):</p>
<p><code>bash
python -m examples.benchmark_canonical --scenario synthetic_dense \
  --n 5000 --d 400 --repeats 2 --eps 0.25 --threads-compare 1,2 --json \
  --out-json bench_canonical_dense.json</code></p>
<p>Recsys-like tall-skinny scenario (nâ‰ˆ500k, dâ‰ˆ200):</p>
<p><code>bash
python -m examples.benchmark_canonical --scenario recsys_like \
  --n 500000 --d 200 --repeats 3 --eps 0.25 --threads-compare 1,2 --json \
  --out-json results/bench_recsys_like.json</code></p>
<p>Ill-conditioned dense scenario (nâ‰ˆ20k, dâ‰ˆ200):</p>
<p><code>bash
python -m examples.benchmark_canonical --scenario ill_conditioned \
  --n 20000 --d 200 --repeats 3 --eps 0.25 --threads-compare 1,2 --json \
  --out-json results/bench_ill_cond.json</code></p>
<p>Recommendation helper (choose Îµ/compression/threads for your regime):</p>
<p><code>bash
rcfd-pcg --d 200 --sparse --density 0.05 --recommend --json</code></p>
<h3 id="demo-service-optional">Demo service (optional)</h3>
<p><code>bash
pip install fastapi uvicorn
uvicorn examples.service:app --host 0.0.0.0 --port 8000</code></p>
<p>Hardening knobs (env):
- <code>RCFD_SERVICE_MAX_BODY</code> (bytes, default 5_000_000)
- <code>RCFD_SERVICE_SOLVE_TIMEOUT_S</code> (float seconds, default 15.0)
- <code>RCFD_SERVICE_REQUIRE_TOKEN=1</code> and <code>RCFD_SERVICE_TOKEN=...</code></p>
<p>Example request:</p>
<p><code>bash
curl -X POST "http://localhost:8000/solve" \
  -H "Content-Type: application/json" \
  -H "x-token: $RCFD_SERVICE_TOKEN" \
  -d '{"A": [[1.0,2.0],[3.0,4.0]], "b": [1.0,0.0], "eps": 0.25, "tol": 1e-6}'</code></p>
<h2 id="regime-chooser-quick-guidance">Regime chooser (quick guidance)</h2>
<ul>
<li>Sparse, moderate d (128 â‰¤ d â‰¤ 512; density â‰¤ 0.05)</li>
<li>Use: <code>--eps auto</code> (â†’ Îµâ‰ˆ0.15), randomized compression with oversamplingâ‰ˆ12 and powerâ‰ˆ1, <code>--threads 2</code></li>
<li>Example: <code>rcfd-pcg --n 20000 --d 200 --sparse --eps auto --json</code></li>
<li>Larger d or denser matrices</li>
<li>Use: <code>--eps auto</code> (Îµâ‰ˆ0.25 up to d&lt;2048, else 0.35), randomized compression with oversampling 8â€“12, power 0â€“1, <code>--threads 1</code></li>
<li>Example: <code>rcfd-pcg --n 100000 --d 1000 --sparse --eps auto --json</code></li>
<li>Exact compression fallback</li>
<li>For small dense d&lt;256, exact eigendecomp (<code>--compression eigh</code>) can be competitive; an incremental variant <code>--compression eigh_inc</code> is also available.</li>
<li>Preconditioner ridge floor</li>
<li>Keep <code>--precond-min-ridge 1e-7</code> unless you see SPD failures (raise slightly) or oversmoothing (lower slightly).</li>
</ul>
<h2 id="python-api">Python API</h2>
<p>```python
import numpy as np
from rcfd_pcg import build_rcfd_sketch, rcfd_pcg_solve, SyntheticProblem</p>
<p>problem = SyntheticProblem(num_rows=200_000, num_cols=500, noise_std=0.0, make_sparse=True)
A, b, x_true = problem.make()
x, diag = rcfd_pcg_solve(A, b, ridge_lambda=0.0, epsilon=0.25, tol=1e-6, return_diagnostics=True, count_spmv=True)
print(diag)</p>
<h3 id="scipy-linearoperator-drop-in">SciPy LinearOperator drop-in</h3>
<p><code>python
from rcfd_pcg.linop import cg_solve_normal_eq
x, diag = cg_solve_normal_eq(A, b, ridge_lambda=0.0, tol=1e-6, max_iter=200, use_rcfd_preconditioner=True, rcfd_eps=0.25)</code></p>
<h3 id="scikit-learn-style-api">scikit-learn style API</h3>
<p><code>python
from rcfd_pcg.sklearn import RCFDRidge
model = RCFDRidge(lam=0.0, eps=0.25, tol=1e-6, max_iter=200, fit_intercept=False)
model.fit(A, b)
pred = model.predict(A)</code></p>
<h3 id="scikit-learn-persistence-saveload">scikit-learn persistence (save/load)</h3>
<p>```python
from rcfd_pcg.sklearn import RCFDRidge
import joblib</p>
<p>model = RCFDRidge(lam=0.0, eps=0.25, tol=1e-6, fit_intercept=False)
model.fit(A, b)
model.save("rcfd_ridge.joblib")  # requires: pip install joblib</p>
<p>loaded = RCFDRidge.load("rcfd_ridge.joblib")
pred = loaded.predict(A)
```</p>
<h2 id="ablations">Ablations</h2>
<p>```bash
rcfd-ablate --n 20000 --d 200 --sparse --repeats 1</p>
<h1 id="save-csv">Save CSV</h1>
<p>rcfd-ablate --n 20000 --d 200 --sparse --repeats 1 --out-csv ablation.csv
```</p>
<h2 id="preconditioner-reuse-saveload-with-json">Preconditioner reuse (save/load) with JSON</h2>
<p>Saving and reusing the preconditioner can reduce total runtime when solving multiple times on the same <code>A</code>.</p>
<p>```powershell</p>
<h1 id="first-run-build-and-save-preconditioner">First run: build and save preconditioner</h1>
<p>rcfd-pcg --n 20000 --d 200 --sparse --eps 0.25 --tol 1e-6 --save-precond pre.npz --json</p>
<h1 id="subsequent-run-load-and-reuse-preconditioner">Subsequent run: load and reuse preconditioner</h1>
<p>rcfd-pcg --n 20000 --d 200 --sparse --eps 0.25 --tol 1e-6 --load-precond pre.npz --json
```</p>
<p>Example JSON (truncated) showing reduced sketch/Cholesky times on reuse:</p>
<p><code>json
{
  "iterations": 36,
  "time_total": 0.312,
  "time_sketch": 0.158,
  "time_cholesky": 0.042,
  "time_pcg": 0.108,
  "preconditioner": {"action": "saved", "path": "pre.npz"}
}</code></p>
<p><code>json
{
  "iterations": 36,
  "time_total": 0.173,
  "time_sketch": 0.0,
  "time_cholesky": 0.0,
  "time_pcg": 0.171,
  "preconditioner": {"action": "loaded", "path": "pre.npz"}
}</code></p>
<h3 id="pipeline-example-with-sparse-csr-features">Pipeline example with sparse CSR features</h3>
<p>```python
import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from rcfd_pcg.sklearn import RCFDRidge</p>
<p>df = pd.DataFrame({
    "cat": ["a", "b", "a", "c"],
    "num1": [0.1, 1.2, -0.3, 2.4],
    "num2": [5.0, 3.3, 1.1, 0.0],
})
y = np.array([1.0, 0.0, 1.0, 0.0])</p>
<p>pre = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=True), ["cat"]),
        ("num", StandardScaler(with_mean=False), ["num1", "num2"])  # keep sparse-friendly
    ],
    sparse_threshold=0.1,
)</p>
<p>pipe = Pipeline([
    ("prep", pre),
    ("model", RCFDRidge(lam=0.0, eps=0.25, tol=1e-6, fit_intercept=False, sketch_dtype="float32")),
])</p>
<h1 id="direct-fit-auto-bail-out-is-enabled-by-default">Direct fit (auto bail-out is enabled by default)</h1>
<p>pipe.fit(df, y)
print("bail_out?", pipe.named_steps["model"].diagnostics_.get("bail_out"))
pred = pipe.predict(df)</p>
<h1 id="optional-hyperparameter-search-tune-epsilon-and-the-bail-out-guardrail">Optional hyperparameter search: tune epsilon and the bail-out guardrail</h1>
<p>search = GridSearchCV(
    pipe,
    param_grid={
        "model__eps": [0.15, 0.25],
        "model__bail_out_threshold": [4.0, 5.0],
        "model__auto_bail_out": [True],
    },
    cv=3,
    scoring="neg_mean_squared_error",
    n_jobs=1,
)
search.fit(df, y)
print("best params:", search.best_params_)
best_model = search.best_estimator_.named_steps["model"]
print("bail_out after search?", best_model.diagnostics_.get("bail_out"))</p>
<h2 id="changelog">Changelog</h2>
<ul>
<li>0.1.0</li>
<li>GA prep: add one-command proof-pack pipeline (<code>scripts/proof_pack_pipeline.py</code>) and integrate proof-pack aggregator into docs and quickstarts.</li>
<li>Guardrails: expose <code>--bail-out-threshold</code>, surface <code>bail_out</code>/<code>bail_out_details</code> in CLI/bench outputs, add sklearn knobs and cookbook examples.</li>
<li>Packaging: bump version to 0.1.0; CI workflows publish to TestPyPI on <code>*-rc</code> tags and PyPI on final tags with attestations; GHCR workflow tags <code>latest</code> only on final tags.</li>
<li>
<p>Proof-pack artifacts refreshed; <code>results/index.html</code> regenerated; plots updated.</p>
</li>
<li>
<p>0.0.3</p>
</li>
<li>CLI: fix HTML summary table rendering in demo/report output.</li>
<li>Benchmarks: clarify canonical sparse single-shot and reuse commands; refreshed artifacts.</li>
<li>Packaging: version bump and local wheel/sdist build verification.</li>
<li>0.0.2</li>
<li>Add BLAS thread limiting during Python-parallel regions to avoid oversubscription.</li>
<li>Bench: add Dense-QR and Dense-Cholesky baselines (toggle with <code>--dense-baselines on|off|auto</code>).</li>
<li>Heuristics: prefer oversamplingâ‰ˆ12 for moderate d (128â€“512).</li>
<li>Fix ablation CSV headers and plumb <code>--threads_grid</code> through to solver (<code>parallel_blocks</code>).</li>
<li>Bench CLI: pass <code>atol=0</code> to SciPy <code>cg</code> to avoid deprecation warnings.</li>
<li>sklearn: include <code>sketch_dtype</code> in <code>get_params</code> for proper round-tripping.</li>
<li>CI: add GitHub Actions for tests (Windows/Ubuntu) with coverage; add wheel build workflow for releases.</li>
<li>0.0.1</li>
<li>Initial MVP: solver/CLIs, docs, tests, notebooks.</li>
</ul>
<h3 id="windows-consoles">Windows consoles</h3>
<p>On Windows, prefer <code>--json</code>, or pass <code>--ascii</code>/<code>--ascii-default</code>, or set UTF-8 encoding to avoid Unicode issues in CLI output:</p>
<p><code>powershell
$env:PYTHONIOENCODING='utf-8'; [Console]::OutputEncoding = [System.Text.UTF8Encoding]::new(); chcp 65001 | Out-Null
rcfd-bench --n 20000 --d 200 --sparse --eps 0.25 --tol 1e-6 --repeats 3 --json</code></p>
<h2 id="notes">Notes</h2>
<ul>
<li>Deterministic single-pass sketch; preconditioner from B^T B + Î» I.</li>
<li>PCG on normal equations; 2 SpMVs/iter.</li>
<li>For large d, consider batching/shrink cadence tuning.</li>
</ul>
<h2 id="docs-index">Docs index</h2>
<ul>
<li>Benchmark Guide: <code>docs/BenchmarkGuide.md</code></li>
<li>Start here: <code>docs/StartHere.md</code></li>
<li>Regime Cookbook: <code>docs/RegimeCookbook.md</code> (parameter tables and commands)</li>
<li>Dataset Gallery: <code>docs/Datasets.md</code></li>
<li>API Reference: <code>docs/API.md</code></li>
<li>Preconditioner Cache: <code>docs/PreconditionerCache.md</code></li>
<li>Support Matrix: <code>docs/SupportMatrix.md</code></li>
<li>Threading &amp; BLAS Guide: <code>docs/ThreadsAndBLAS.md</code></li>
<li>Verification (hash/digest): <code>docs/Verification.md</code></li>
<li>Weights/WLS notes: <code>docs/WeightsWLS.md</code></li>
</ul>
<h2 id="release-checklist-maintainers">Release checklist (maintainers)</h2>
<ul>
<li>Bump version in <code>pyproject.toml</code> and update changelog/README highlights.</li>
<li>Ensure <code>PYPI_API_TOKEN</code> secret is set for the repo (pypi <code>__token__</code> scoped to the project).</li>
<li>Create and push tag <code>vX.Y.Z</code>; the wheels workflow will publish to PyPI automatically.</li>
<li>Trigger the Docker workflow (auto on tag, or <code>gh workflow run docker.yml --ref vX.Y.Z</code>) to push <code>ghcr.io/alexanderluzdh/rcfd</code> images.</li>
<li>Verify artifacts: install from PyPI (<code>pip install rcfd-pcg==X.Y.Z</code>) and pull the GHCR image (<code>docker pull ghcr.io/alexanderluzdh/rcfd:vX.Y.Z</code>).</li>
<li>Regenerate <code>results/index.html</code>/plots if benchmarks changed, then update <code>README.md</code> and <code>ROADMAP.md</code> as needed.</li>
</ul>
<h2 id="license-status">License status</h2>
<p>Check your token quickly:</p>
<p>`ash
rcfd-license --json
``n</p></body></html>